# Product Context

**Problem Space:** The NVIDIA Managed AI Research Supercluster team needs to "reduce operational disruption and overhead" for internal researchers using large-scale GPU clusters. A key pain point is validating, monitoring, and operating these clusters at scale. The job description explicitly calls for solutions that "empower them for self-service continuous improvement on reliability, operational excellence & performance."

**Our Solution ("GPU Watchdog"):** This project is a direct, miniature prototype of a solution to that exact problem.

*   **As a Product:** It's a self-service monitoring platform that provides real-time visibility into GPU utilization and health, reducing the need for researchers to manually inspect nodes. The integrated "Agentic AI" component provides diagnostic capabilities, further reducing the operational toil of the SRE team.

*   **As an Interview Preparation Tool:** Every component is designed to create a tangible talking point for the user's specific interview schedule. It bridges the user's existing strengths in full-stack development with the key missing domains required for the role: GPU infrastructure, AIOps, and HPC schedulers (Slurm).
